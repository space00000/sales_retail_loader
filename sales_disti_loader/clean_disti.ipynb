{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "#Carpetas donde se encuentran los archivos\n",
    "\n",
    "retail_data_path = 'C:/Users/GERARDITO/OneDrive - ASUS/Python/distributor_data_cleaner/Input/'\n",
    "\n",
    "input_ingram = os.path.join(retail_data_path, 'INGRAM.xlsx')\n",
    "\n",
    "input_ingram_stock = os.path.join(retail_data_path, 'INGRAM STOCK.xlsx')\n",
    "\n",
    "input_intcomex = os.path.join(retail_data_path, 'INTCOMEX.xlsx')\n",
    "\n",
    "input_intcomex_stock = os.path.join(retail_data_path, 'INTCOMEX STOCK.xlsx')\n",
    "\n",
    "input_nexsys = os.path.join(retail_data_path, 'NEXSYS.xlsx')\n",
    "\n",
    "# Variable global para obtener el ultimo dataframe limpiado\n",
    "\n",
    "df_disti_sales = pd.DataFrame()\n",
    "\n",
    "df_disti_stock = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GERARDITO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Conexion a database para obtener id\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    database='asus_db',\n",
    "    user='postgres',\n",
    "    password='GitsyLipsy6853',\n",
    "    port='5432'\n",
    ")\n",
    "\n",
    "sql_command = \"\"\" SELECT * FROM importer\"\"\"\n",
    "\n",
    "df_importer = pd.read_sql(sql_command, connection)\n",
    "\n",
    "df_importer = df_importer.rename(columns={'id':'importer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_intcomex():\n",
    "\n",
    "    #Sales formatting\n",
    "\n",
    "    intcomex_sales = pd.read_excel(input_intcomex)\n",
    "\n",
    "    df = pd.DataFrame(intcomex_sales)\n",
    "\n",
    "    df = df.rename(columns={'Trans Date':'date',\n",
    "                                 'Ship Qty':'sell_out_units',\n",
    "                                 'Unit Initial Cost US':'sales_cost',\n",
    "                                 'CustomerID':'buyer_code',\n",
    "                                 'SKU':'sku'})\n",
    "\n",
    "    df['importer_name'] = 'Intcomex'\n",
    "\n",
    "    df['sell_out_value'] = df['sell_out_units'] * df['sales_cost']\n",
    "\n",
    "    df = df[df['sku'].notna()]\n",
    "\n",
    "    df = df[['date','importer_name','sku','sell_out_units','sell_out_value','buyer_code']]\n",
    "\n",
    "    #Stock\n",
    "\n",
    "    intcomex_stock = pd.read_excel(input_intcomex_stock, header = 2)\n",
    "\n",
    "    df1 = pd.DataFrame(intcomex_stock)\n",
    "\n",
    "    #Obtener fecha del domingo\n",
    "\n",
    "    day_s = df['date'].iloc[0].strftime(\"%d-%m-%Y\")\n",
    "    dt1 = dt.strptime(day_s, '%d-%m-%Y')\n",
    "    start = dt1 - timedelta(days=dt1.weekday())\n",
    "    end_week = start + timedelta(days=6)\n",
    "\n",
    "    df1['date'] = end_week\n",
    "\n",
    "    df1['importer_name'] = 'Intcomex'\n",
    "\n",
    "    df1 = df1.rename(columns={'OH':'stock_units',\n",
    "                                 'InitialCostUS':'stock_cost',\n",
    "                                 'SKU':'sku'})\n",
    "\n",
    "    df1['stock_value'] = df1['stock_units'] * df1['stock_cost']\n",
    "\n",
    "    df1 = df1[['date','importer_name','sku','stock_units','stock_value']]\n",
    "\n",
    "    index_names = df1[ (df1['stock_units'] == 0) & (df1['stock_value'] == 0)].index\n",
    "    df1.drop(index_names, inplace= True)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    df1['date'] = pd.to_datetime(df1['date']).dt.date\n",
    "\n",
    "    global df_disti_stock\n",
    "\n",
    "    global df_disti_sales\n",
    "\n",
    "    df = pd.merge(df1,df_importer[['importer_name','importer_id']],left_on='importer_name', right_on='importer_name', how='inner')\n",
    "\n",
    "    df1 = pd.merge(df1,df_importer[['importer_name','importer_id']],left_on='importer_name', right_on='importer_name', how='inner')\n",
    "\n",
    "    df_disti_sales = df\n",
    "\n",
    "    df_disti_stock = df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74a27ae9c900ac01cd3d90349cab9c014337781a9593577a26f65574ac168aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
